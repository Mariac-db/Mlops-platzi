{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import joblib\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model building baseline with mlflow tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_name: str, path=\"data/data_processed\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read csv file\n",
    "    :param file_name: file name\n",
    "    :param path: path to the file\n",
    "    :return: pandas dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_csv(os.path.join(path, file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets = read_csv(\"tickets_inputs_eng_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tickets.relevant_topics.value_counts() #positivo para desbalance but, la vida es asÃ­ y hay que seguir adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///backend.db\")\n",
    "mlflow.set_experiment(\"tickets_baseline\")\n",
    "\n",
    "\n",
    "def data_transform(df: pd.DataFrame):\n",
    "    \"\"\"This function transform the data into X and y\n",
    "    Args:\n",
    "      df (pd.DataFrame): dataframe with the data\n",
    "    Returns:\n",
    "      X (pd.Series): series with the text\n",
    "      y (pd.Series): series with the labels\"\"\"\n",
    "    X = df[\"processed_text\"]\n",
    "    y = df[\"relevant_topics\"]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def read_idx2label(json_path: str) -> pd.Series:\n",
    "    \"\"\"This function read the json file and return a dictionary\n",
    "    Args:\n",
    "      json_path (str): path to the json file\n",
    "     Returns:\n",
    "      idx2label (dict): dictionary with the mapping\"\"\"\n",
    "    with open(json_path) as f:\n",
    "        idx2label = json.load(f)\n",
    "    return idx2label\n",
    "\n",
    "\n",
    "def decode_labels_into_idx(labels: pd.Series, idx2label: dict) -> pd.Series:\n",
    "    \"\"\"This function decode the labels into idx\n",
    "    Args:\n",
    "      labels (pd.Series): series with the labels\n",
    "      idx2label (dict): dictionary with the mapping\n",
    "     Returns:\n",
    "      labels (pd.Series): series with the labels decoded\n",
    "    \"\"\"\n",
    "    return labels.map(idx2label)\n",
    "\n",
    "\n",
    "def fit_transform(X: pd.Series) -> np.ndarray:\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    X_vectorized = count_vectorizer.fit_transform(X)\n",
    "    #save count vectorizer for data preprocessing in the main app (deploy)\n",
    "    joblib.dump(count_vectorizer, 'data/data_processed/count_vectorizer.pkl')\n",
    "    logger.info(\"count vectorizer trained successfully stored\")\n",
    "    return X_vectorized\n",
    "\n",
    "\n",
    "def transform_tfidf(X_vectorized: object) -> np.ndarray:\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_tfidf = tfidf_transformer.fit_transform(X_vectorized)\n",
    "    joblib.dump(X_tfidf, 'data/data_processed/X_tfidf.pkl')\n",
    "    logger.info(\"X_tfidf trained successfully stored\")\n",
    "    return X_tfidf\n",
    "\n",
    "def split_train_test(\n",
    "    X_tfidf: np.array, y: pd.Series, test_size: float = 0.3, random_state: int = 42\n",
    ") -> tuple:\n",
    "    \"\"\"This function split the data into train and test\n",
    "    Args:\n",
    "      X_tfidf (np.array): array with the vectorized data\n",
    "      y (pd.Series): series with the labels\n",
    "      test_size (float): test size\n",
    "      random_state (int): random state\n",
    "     Returns:\n",
    "      X_train (np.array): array with the vectorized data for train\n",
    "      X_test (np.array): array with the vectorized data for test\n",
    "      y_train (pd.Series): series with the labels for train\n",
    "      y_test (pd.Series): series with the labels for test\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_tfidf, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def display_classification_report(\n",
    "    model: object,\n",
    "    name_model: str,\n",
    "    developer: str,\n",
    "    X_train: np.array,\n",
    "    X_test: np.array,\n",
    "    y_train: np.array,\n",
    "    y_test: np.array,\n",
    "    use_cv = False\n",
    "):\n",
    "    \"\"\"This function display the classification report\n",
    "    Args:\n",
    "      model (object): model\n",
    "      X_train (np.array): array with the vectorized data for train\n",
    "      X_test (np.array): array with the vectorized data for test\n",
    "      y_train (pd.Series): series with the labels for train\n",
    "      y_test (pd.Series): series with the labels for test\n",
    "     Returns:\n",
    "      metric (list): list with the metrics\"\"\"\n",
    "\n",
    "    with mlflow.start_run(run_name=name_model):\n",
    "        mlflow.log_param(\"model\", name_model)\n",
    "        mlflow.log_param(\"developer\", developer)\n",
    "\n",
    "        metric = []\n",
    "        y_train_pred_proba = model.predict_proba(X_train)\n",
    "        y_test_pred_proba = model.predict_proba(X_test)\n",
    "        roc_auc_score_train = round(\n",
    "            roc_auc_score(\n",
    "                y_train, y_train_pred_proba, average=\"weighted\", multi_class=\"ovr\"\n",
    "            ),\n",
    "            2,\n",
    "        )\n",
    "        roc_auc_score_test = round(\n",
    "            roc_auc_score(\n",
    "                y_test, y_test_pred_proba, average=\"weighted\", multi_class=\"ovr\"\n",
    "            ),\n",
    "            2,\n",
    "        )\n",
    "\n",
    "        print(\"ROC AUC Score Train:\", roc_auc_score_train)\n",
    "        print(\"ROC AUC Score Test:\", roc_auc_score_test)\n",
    "        metric.extend([roc_auc_score_train, roc_auc_score_test])\n",
    "\n",
    "        mlflow.log_metric(\"roc_auc_train\", roc_auc_score_train)\n",
    "        mlflow.log_metric(\"roc_auc_test\", roc_auc_score_test)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        (\n",
    "            precision_train,\n",
    "            recall_train,\n",
    "            fscore_train,\n",
    "            support_train,\n",
    "        ) = precision_recall_fscore_support(y_train, y_train_pred, average=\"weighted\")\n",
    "        (\n",
    "            precision_test,\n",
    "            recall_test,\n",
    "            fscore_test,\n",
    "            support_test,\n",
    "        ) = precision_recall_fscore_support(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "        mlflow.log_metric(\"precision_train\", precision_train)\n",
    "        mlflow.log_metric(\"precision_test\", precision_test)\n",
    "        mlflow.log_metric(\"recall_train\", recall_train)\n",
    "        mlflow.log_metric(\"recall_test\", recall_test)\n",
    "        \n",
    "        try:\n",
    "            if use_cv:\n",
    "                best_params = model.best_params_\n",
    "            else:\n",
    "                best_params = model.get_params()\n",
    "            mlflow.log_params(best_params)\n",
    "\n",
    "        except AttributeError as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "        acc_score_train = round(accuracy_score(y_train, y_train_pred), 2)\n",
    "        acc_score_test = round(accuracy_score(y_test, y_test_pred), 2)\n",
    "\n",
    "        metric.extend(\n",
    "            [\n",
    "                acc_score_train,\n",
    "                acc_score_test,\n",
    "                round(precision_train, 2),\n",
    "                round(precision_test, 2),\n",
    "                round(recall_train, 2),\n",
    "                round(recall_test, 2),\n",
    "                round(fscore_train, 2),\n",
    "                round(fscore_test, 2),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(\"Train Accuracy: \", acc_score_train)\n",
    "        print(\"Test Accuracy: \", acc_score_test)\n",
    "\n",
    "        model_report_train = classification_report(y_train, y_train_pred)\n",
    "        model_report_test = classification_report(y_test, y_test_pred)\n",
    "\n",
    "        print(\"Classification Report for Train:\\n\", model_report_train)\n",
    "        print(\"Classification Report for Test:\\n\", model_report_test)\n",
    "\n",
    "        # Plot the confusion matrix\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "        # Create the confusion matrix with labels decoded\n",
    "        decoded_y_test_pred = [idx2label[idx] for idx in y_test_pred]\n",
    "        decoded_y_test = [idx2label[idx] for idx in y_test]\n",
    "\n",
    "        cm = confusion_matrix(decoded_y_test, decoded_y_test_pred)\n",
    "        cmp = ConfusionMatrixDisplay(cm, display_labels=list(idx2label.values()))\n",
    "        cmp.plot(ax=ax)\n",
    "\n",
    "        plt.xticks(rotation=80)\n",
    "        plt.show()\n",
    "\n",
    "        mlflow.sklearn.log_model(model, f\"models/{name_model}\")\n",
    "\n",
    "        return metric\n",
    "\n",
    "\n",
    "def grid_search(model, folds, params, scoring):\n",
    "    \"\"\"This function perform a grid search\n",
    "    Args:\n",
    "        model (object): model\n",
    "        folds (int): number of folds\n",
    "        params (dict): dictionary with the parameters\n",
    "        scoring (str): scoring\n",
    "    Returns:\n",
    "        grid_search (object): grid search\n",
    "    \"\"\"\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model, cv=folds, param_grid=params, scoring=scoring, n_jobs=-1, verbose=1\n",
    "    )\n",
    "    return grid_search\n",
    "\n",
    "\n",
    "def print_best_score_params(model):\n",
    "    \"\"\"This functions print best score and best hyperparameters for baselines models\n",
    "    Args:\n",
    "        model (object): model\n",
    "    Returns:\n",
    "        None\"\"\"\n",
    "    print(\"Best Score: \", model.best_score_)\n",
    "    print(\"Best Hyperparameters: \", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "idx2label = read_idx2label(json_path=\"data/data_processed/topic_mapping_1.json\")\n",
    "label2idx = {value: key for key, value in idx2label.items()}\n",
    "\n",
    "X, y = data_transform(df_tickets)\n",
    "y = decode_labels_into_idx(labels=y, idx2label=label2idx)\n",
    "\n",
    "X_vectorized = fit_transform(X.values)\n",
    "X_tfidf = transform_tfidf(X_vectorized)\n",
    "X_train, X_test, y_train, y_test = split_train_test(X_tfidf, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: pink;\">Modelo Multinomial Naive Bayes</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train, y_train)\n",
    "display_classification_report(model=mnb, \n",
    "                              name_model=\"MultinomialNB\", \n",
    "                              developer=\"Maria\", \n",
    "                              X_train=X_train, \n",
    "                              X_test=X_test, \n",
    "                              y_train=y_train, \n",
    "                              y_test=y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: pink;\">Modelo Multinomial Naive Bayes con GreadSearch</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 40)\n",
    "mnb = MultinomialNB()\n",
    "mnb_params = {  \n",
    "'alpha': (1, 0.1, 0.01, 0.001, 0.0001)  \n",
    "}\n",
    "grid_search_mnb = grid_search(mnb, folds, mnb_params, scoring=None)\n",
    "grid_search_mnb.fit(X_train, y_train)\n",
    "print_best_score_params(grid_search_mnb)\n",
    "\n",
    "display_classification_report(model=grid_search_mnb, \n",
    "                              name_model=\"MultinomialNBCV\", \n",
    "                              developer=\"Maria\", \n",
    "                              X_train=X_train, \n",
    "                              X_test=X_test, \n",
    "                              y_train=y_train, \n",
    "                              y_test=y_test, \n",
    "                              use_cv= True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: pink;\">Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=40,solver='liblinear')\n",
    "log_reg.fit(X_train,y_train)\n",
    "display_classification_report(model=log_reg, \n",
    "                              name_model=\"LogisticRegression\", \n",
    "                              developer=\"Maria\", \n",
    "                              X_train=X_train, \n",
    "                              X_test=X_test, \n",
    "                              y_train=y_train, \n",
    "                              y_test=y_test, \n",
    "                              use_cv=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: pink;\">Logistic Regression with GreadSearch</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_params = {'C': [0.01, 1, 10], \n",
    "          'penalty': ['l1', 'l2'],\n",
    "          'solver': ['liblinear','newton-cg','saga']\n",
    "         }\n",
    "grid_search_log = grid_search(log_reg, folds, log_params, scoring=None)\n",
    "grid_search_log.fit(X_train, y_train)\n",
    "print_best_score_params(grid_search_log)\n",
    "display_classification_report(grid_search_log,\n",
    "                              name_model=\"LogisticRegressionCV\", \n",
    "                              developer=\"Maria\", \n",
    "                              X_train=X_train, \n",
    "                              X_test=X_test, \n",
    "                              y_train=y_train, \n",
    "                              y_test=y_test, \n",
    "                              use_cv=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: pink;\">Decision Tree Classifier</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=40)\n",
    "dtc.fit(X_train,y_train)\n",
    "display_classification_report(model=dtc,\n",
    "                              name_model=\"DecisionTreeClassifier\",\n",
    "                              developer=\"Maria\",\n",
    "                              X_train=X_train,\n",
    "                              X_test=X_test,\n",
    "                              y_train=y_train,\n",
    "                              y_test=y_test,\n",
    "                              use_cv=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color: pink;\">Decision Tree Classifier with Gread Search</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decis|on tree classifier with grid search\n",
    "dtc_cv = DecisionTreeClassifier(random_state=40)\n",
    "dtc_params = {\n",
    "    'max_depth': [2,3,4,5],\n",
    "    'min_samples_leaf': [2,3,4,7]\n",
    "}\n",
    "\n",
    "grid_search_dtc = grid_search(dtc_cv, folds, dtc_params, scoring='roc_auc_ovr')\n",
    "grid_search_dtc.fit(X_train, y_train)\n",
    "print_best_score_params(grid_search_dtc)\n",
    "display_classification_report(grid_search_dtc, \n",
    "                              name_model=\"DecisionTreeClassifierCV\", \n",
    "                              developer=\"Maria\", \n",
    "                              X_train=X_train, \n",
    "                              X_test=X_test, \n",
    "                              y_train=y_train, \n",
    "                              y_test=y_test, \n",
    "                              use_cv=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-curso-py3.9",
   "language": "python",
   "name": "mlops-curso-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
